# -*- coding: utf-8 -*-
"""Underwater plastic waste detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RDzW1zRdVu00OyFGamvdFeRagFTY6H09
"""

from google.colab import files

# Upload kaggle.json
files.upload()

!mkdir -p ~/.kaggle  # Create a directory for Kaggle API key
!mv kaggle.json ~/.kaggle/  # Move the file to the correct location
!chmod 600 ~/.kaggle/kaggle.json  # Set permissions

!kaggle datasets download -d arnavs19/underwater-plastic-pollution-detection --unzip -p /content/

!pip install ultralytics
from ultralytics import YOLO
import torch

# Check if GPU is available, otherwise use CPU
device = 0 if torch.cuda.is_available() else "cpu"

# Load YOLO model with transferred weights
Final_model = YOLO("yolov8n.yaml").load("yolov8n.pt")

# Train the model
Result_Final_model = Final_model.train(
    data="/content/underwater_plastics/data.yaml",  # Ensure this file exists and is correct
    epochs=75,
    imgsz=640,
    batch=16,
    lr0=0.01,
    dropout=0.15,
    device=device  # Use auto-detected device
)

import os

dataset_path = "/content/underwater_plastics/train"

try:
    files = os.listdir(dataset_path)
    print("Files in dataset directory:", files)
except Exception as e:
    print("Error:", e)

from glob import glob
import matplotlib.pyplot as plt
import cv2

# Path to the results
list_of_metrics = ["P_curve.png", "R_curve.png", "confusion_matrix.png"]
for i in list_of_metrics:
    # img = cv2.imread(f"/content/runs/detect/train/{i}")
    img=cv2.imread(f"/content/runs/detect/train/{i}")
     # Update path as needed
    plt.figure(figsize=(16, 12))
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.axis("off")
    plt.show()

!find /content -name best.pt
from google.colab import files
files.download('/content/runs/detect/train/weights/best.pt')

metrics = Final_model.val(split='test')
print(metrics)  # Outputs mAP, Precision, Recall, etc.

import pandas as pd
results = pd.read_csv("/content/runs/detect/train/results.csv")

results.head()

import seaborn as sns

results.columns = results.columns.str.strip()
# Create subplots
fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(15, 15))

# Plot the columns using seaborn
sns.lineplot(x='epoch', y='train/box_loss', data=results, ax=axs[0,0])
sns.lineplot(x='epoch', y='train/cls_loss', data=results, ax=axs[0,1])
sns.lineplot(x='epoch', y='train/dfl_loss', data=results, ax=axs[1,0])
sns.lineplot(x='epoch', y='metrics/precision(B)', data=results, ax=axs[1,1])
sns.lineplot(x='epoch', y='metrics/recall(B)', data=results, ax=axs[2,0])
sns.lineplot(x='epoch', y='metrics/mAP50(B)', data=results, ax=axs[2,1])
sns.lineplot(x='epoch', y='metrics/mAP50-95(B)', data=results, ax=axs[3,0])
sns.lineplot(x='epoch', y='val/box_loss', data=results, ax=axs[3,1])
sns.lineplot(x='epoch', y='val/cls_loss', data=results, ax=axs[4,0])
sns.lineplot(x='epoch', y='val/dfl_loss', data=results, ax=axs[4,1])

# Set titles and axis labels for each subplot
axs[0,0].set(title='Train Box Loss')
axs[0,1].set(title='Train Class Loss')
axs[1,0].set(title='Train DFL Loss')
axs[1,1].set(title='Metrics Precision (B)')
axs[2,0].set(title='Metrics Recall (B)')
axs[2,1].set(title='Metrics mAP50 (B)')
axs[3,0].set(title='Metrics mAP50-95 (B)')
axs[3,1].set(title='Validation Box Loss')
axs[4,0].set(title='Validation Class Loss')
axs[4,1].set(title='Validation DFL Loss')

plt.suptitle('Training Metrics and Loss', fontsize=24)
plt.subplots_adjust(top=0.8)
plt.tight_layout()
plt.show()

# Loading the best performing model
Valid_model = YOLO('/content/runs/detect/train/weights/best.pt')

# Evaluating the model on the testset
metrics = Valid_model.val(split = 'test')

# final results
print("precision(B): ", metrics.results_dict["metrics/precision(B)"])
print("metrics/recall(B): ", metrics.results_dict["metrics/recall(B)"])
print("metrics/mAP50(B): ", metrics.results_dict["metrics/mAP50(B)"])
print("metrics/mAP50-95(B): ", metrics.results_dict["metrics/mAP50-95(B)"])

from PIL import Image

images = os.listdir("/content/underwater_plastics/test/images")
for i in range(15):
    image = os.path.join("/content/underwater_plastics/test/images", images[i])
    result_predict = Valid_model.predict(source = image, imgsz=(640), iou=0.4)

    # show results
    plot = result_predict[0].plot()
    plot = cv2.cvtColor(plot, cv2.COLOR_BGR2RGB)
    display(Image.fromarray(plot))

from PIL import Image
import cv2

# Path to your new image (replace with your image path)
image_path = "/test1.jpg"

# Run prediction on new image
result_predict = Valid_model.predict(source=image_path, imgsz=640, iou=0.4)

# Display the result
if result_predict and len(result_predict) > 0:
    plot = result_predict[0].plot()
    if plot is not None:
        plot = cv2.cvtColor(plot, cv2.COLOR_BGR2RGB)
        display(Image.fromarray(plot))
    else:
        print("Warning: No visual output for the image.")
else:
    print("Error: Model did not return predictions.")

from PIL import Image
import cv2

# Path to your new image (replace with your image path)
image_path = "/test2.jpg"

# Run prediction on new image
result_predict = Valid_model.predict(source=image_path, imgsz=640, iou=0.4)

# Display the result
if result_predict and len(result_predict) > 0:
    plot = result_predict[0].plot()
    if plot is not None:
        plot = cv2.cvtColor(plot, cv2.COLOR_BGR2RGB)
        display(Image.fromarray(plot))
    else:
        print("Warning: No visual output for the image.")
else:
    print("Error: Model did not return predictions.")

from google.colab import files
files.download('runs/detect/train/weights/best.pt')

