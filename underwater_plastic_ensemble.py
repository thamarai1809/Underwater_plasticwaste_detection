# -*- coding: utf-8 -*-
"""ensemble.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_j2har5oW5-RH2TLQfy01OOeE-fFUqUF
"""

from google.colab import files

# Upload kaggle.json
files.upload()

!mkdir -p ~/.kaggle  # Create a directory for Kaggle API key
!mv kaggle.json ~/.kaggle/  # Move the file to the correct location
!chmod 600 ~/.kaggle/kaggle.json  # Set permissions

!kaggle datasets download -d arnavs19/underwater-plastic-pollution-detection --unzip -p /content/

!pip install ultralytics

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random

from ultralytics import YOLO
from collections import Counter
from glob import glob
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

# ==== Label Map ====
label_map = {
    0: 'Mask',
    1: 'can',
    2: 'cellphone',
    3: 'electronics',
    4: 'gbottle',
    5: 'glove',
    6: 'metal',
    7: 'misc',
    8: 'net',
    9: 'pbag',
    10: 'pbottle',
    11: 'plastic',
    12: 'rod',
    13: 'sunglasses',
    14: 'tire'
}

# ==== 1. YOLOv8 Inference Function ====
def get_yolo_predictions(img, conf_thresh=0.1):
    results = yolo_model.predict(img, conf=conf_thresh, verbose=False)
    crops = []
    labels = []

    for result in results:
        if result.boxes is None:
            continue
        for box in result.boxes:
            if box.conf[0] < conf_thresh:
                continue  # skip low-confidence boxes

            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
            cls = int(box.cls[0])
            crop = img[y1:y2, x1:x2]
            if crop.size > 0:
                crops.append(crop)
                labels.append(cls)

    return crops, labels


# ==== 2. Feature Extraction ====
def extract_features(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.resize(gray, (64, 64))
    return gray.flatten()

# ==== 3. Classifier Training ====
def train_classifiers(X, y):
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    svm = SVC(probability=True)
    knn = KNeighborsClassifier()
    rf = RandomForestClassifier()

    svm.fit(X_scaled, y)
    knn.fit(X_scaled, y)
    rf.fit(X_scaled, y)

    return [svm, knn, rf], scaler

# ==== 4. Ensemble with Soft Voting ====
def ensemble_predict_soft(yolo_label, features, classifiers, scaler):
    X_scaled = scaler.transform([features])
    proba_sum = np.zeros(len(label_map))

    for clf in classifiers:
        probs = clf.predict_proba(X_scaled)[0]
        proba_sum += probs

    # Boost YOLO vote by +2 to its class
    proba_sum[yolo_label] += 2
    final_label = np.argmax(proba_sum)
    return final_label

# ==== 5. Confusion Matrix Plot ====
def plot_confusion(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap='Blues')
    plt.title("Confusion Matrix")
    plt.show()

    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title("Confusion Matrix Heatmap")
    plt.show()

# ==== 6. Visualize Predictions ====
def show_predictions(X_test_feats, y_test, y_pred, image_crops, num_samples=6):
    indices = random.sample(range(len(X_test_feats)), min(num_samples, len(X_test_feats)))
    plt.figure(figsize=(15, 5))
    for i, idx in enumerate(indices):
        plt.subplot(2, 3, i+1)
        crop = image_crops[idx]
        true_label = label_map.get(y_test[idx], y_test[idx])
        pred_label = label_map.get(y_pred[idx], y_pred[idx])
        color = "green" if y_test[idx] == y_pred[idx] else "red"
        title = f"True: {true_label} | Pred: {pred_label}"
        plt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))
        plt.title(title, color=color)
        plt.axis("off")
    plt.tight_layout()
    plt.show()

# ==== 7. Load YOLOv8 Model ====
yolo_model = YOLO('/content/best.pt')

# ==== 8. Main Pipeline ====
def main():
    image_paths = glob("/content/underwater_plastics/train/images/*.jpg")
    print(f"Found {len(image_paths)} training images.")

    X, y = [], []
    image_crops = []

    for path in image_paths:
        img = cv2.imread(path)
        if img is None:
            print(f"Failed to read image: {path}")
            continue

        crops, yolo_labels = get_yolo_predictions(img)

        if not crops:
            print(f"No objects found in: {path}")
            continue

        for crop, yolo_label in zip(crops, yolo_labels):
            features = extract_features(crop)
            X.append(features)
            y.append(yolo_label)
            image_crops.append(crop)

    if len(X) == 0:
        print("No training data available after preprocessing. Exiting.")
        return

    X_train, X_test, y_train, y_test, crop_train, crop_test = train_test_split(
        X, y, image_crops, test_size=0.2, random_state=42)

    global classifiers, scaler
    classifiers, scaler = train_classifiers(X_train, y_train)

    # Ensemble Prediction
    y_pred = []
    for feat, true_yolo in zip(X_test, y_test):
        final = ensemble_predict_soft(true_yolo, feat, classifiers, scaler)
        y_pred.append(final)

    print(classification_report(y_test, y_pred, target_names=[label_map[i] for i in sorted(set(y_test))]))
    plot_confusion(y_test, y_pred)
    show_predictions(X_test, y_test, y_pred, crop_test)

# ==== 9. Test on a Single Image ====
def test_single_image(image_path):
    img = cv2.imread(image_path)
    crops, yolo_labels = get_yolo_predictions(img, conf_thresh=0.1)


    if not crops:
        print("No objects detected.")
        return

    for i, (crop, yolo_label) in enumerate(zip(crops, yolo_labels)):
        features = extract_features(crop)
        final = ensemble_predict_soft(yolo_label, features, classifiers, scaler)

        true_name = label_map.get(yolo_label, yolo_label)
        pred_name = label_map.get(final, final)

        plt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))
        plt.title(f"YOLO: {true_name} | Ensemble: {pred_name}",
                  color='green' if true_name == pred_name else 'red')
        plt.axis("off")
        plt.show()

if __name__ == "__main__":
    main()
    # Example usage: test_single_image("/content/underwater_plastics/test/images/example.jpg")

"""## Testing using unseen data"""

test_single_image("/content/test1.jpg")

test_single_image("/content/test2.jpg")

test_single_image("/content/test3.jpeg")

test_single_image("/content/test4.jpeg")

test_single_image("/content/test5.jpeg")

